{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overcast 20191030T161529_VOOR\n",
    "#partly 20191112T183029_VOOR\n",
    "#clear 20190511T122529_VOOR\n",
    "PATH = '/home/arnold/clouds_detection/ALL'\n",
    "data_dir = pathlib.Path(PATH)\n",
    "#resize image \n",
    "# sz=224\n",
    "# List containing the entries in the directory given by PATH\n",
    "os.listdir(PATH)\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)\n",
    "batch_size = 32\n",
    "img_height = 720\n",
    "img_width = 1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle=False)\n",
    "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in list_ds.take(7):\n",
    "  print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #split into training testing and val \n",
    "# val_size = int(image_count * 0.2)\n",
    "# train_ds = list_ds.skip(val_size)\n",
    "# val_ds = list_ds.take(val_size)\n",
    "\n",
    "train_size = int(image_count * 0.8)\n",
    "val_size = int(image_count * 0.15)\n",
    "test_size = int(image_count * 0.05)\n",
    "\n",
    "train_ds = list_ds.take(train_size)\n",
    "test_ds = list_ds.skip(train_size)\n",
    "val_ds = test_ds.skip(test_size)\n",
    "test_ds = test_ds.take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
    "print(tf.data.experimental.cardinality(val_ds).numpy())\n",
    "print(tf.data.experimental.cardinality(test_ds).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "    one_hot = parts[-2] == class_names\n",
    "  # Integer encode the label\n",
    "    return tf.argmax(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "  # resize the image to the desired size\n",
    "    return tf.image.resize(img, [img_height, img_width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "#     img = image.img_to_array(img)\n",
    "    height, width, channels = img.shape\n",
    "#     img = img[0:int(height/3), 0:width] #1/3 top \n",
    "    img = img[0:int(height/2), 0:width] #half\n",
    "    print(img.shape)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "test_ds = test_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train_ds.take(1):\n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  print(\"Label: \", label.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance(ds):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = configure_for_performance(train_ds)\n",
    "val_ds = configure_for_performance(val_ds)\n",
    "test_ds = configure_for_performance(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(test_ds))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "    label = label_batch[i]\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(image_batch[8].numpy().astype(\"uint8\"))\n",
    "\n",
    "# img = PIL.Image.fromarray(image_batch[8].numpy().astype(\"uint8\"))\n",
    "# img.save(\"/home/arnold/clouds_detection/cropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RGB channel values are in the [0, 255] range. Bad for neural network; want input values small. \n",
    "#Standardize values to be in the [0, 1] by using a Rescaling layer.\n",
    "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixels values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Data augmentation - generating additional training data from your existing examples by augmenting then using random transformations that yield believable-looking images\n",
    "# data_augmentation = keras.Sequential(\n",
    "#   [\n",
    "# #       tf.keras.layers.experimental.preprocessing.RandomCrop(\n",
    "# #     240, 1280\n",
    "# # )\n",
    "# #     layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
    "# #                                                  input_shape=(img_height, \n",
    "# #                                                               img_width,\n",
    "# #                                                               3)),\n",
    "#     layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "#     layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "#   ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data_augmentation(image_batch)\n",
    "# #viz augmented images\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, _ in train_ds.take(1):\n",
    "#     for i in range(9):\n",
    "#         augmented_images = data_augmentation(images)\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         plt.title(augmented_images[0].shape)\n",
    "#         plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "print(num_classes, img_height, img_width)\n",
    "\n",
    "#if not doing data augmentation\n",
    "model = Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(360, 1080, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "\n",
    "#if doing data augmentaion\n",
    "# model = Sequential([\n",
    "#   data_augmentation,\n",
    "#   layers.experimental.preprocessing.Rescaling(1./255),\n",
    "#   layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "#   layers.MaxPooling2D(),\n",
    "#   layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "#   layers.MaxPooling2D(),\n",
    "#   layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#   layers.MaxPooling2D(),\n",
    "#   layers.Dropout(0.2),\n",
    "#   layers.Flatten(),\n",
    "#   layers.Dense(128, activation='relu'),\n",
    "#   layers.Dense(num_classes)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model (To view training and validation accuracy for each training epoch, pass the metrics argument)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = '/home/mesonet/cam_photos/2018/08/17/ESSX'\n",
    "# from keras.preprocessing import image\n",
    "\n",
    "# # load all images into a list\n",
    "# paths = []\n",
    "# images = []\n",
    "# for img in os.listdir(folder_path):\n",
    "#     img = os.path.join(folder_path, img)\n",
    "#     paths.append(img)\n",
    "#     img = image.load_img(img, target_size=(img_height, img_width))\n",
    "#     img = image.img_to_array(img)\n",
    "#     height, width, channels = img.shape\n",
    "#     img = img[0:int(height/3), 0:width]\n",
    "#     img = np.expand_dims(img, axis=0)\n",
    "#     images.append(img)\n",
    "# # print(images[1])\n",
    "# # stack up images list to pass for prediction\n",
    "# images = np.vstack(images)\n",
    "# #print(paths)\n",
    "# # for i in paths:\n",
    "# #     PIL.Image.open(i)\n",
    "# #\n",
    "\n",
    "# classes = model.predict_classes(images, batch_size=32)\n",
    "# print(class_names)\n",
    "# print(classes)\n",
    "# predictions = model.predict(images)\n",
    "# score = tf.nn.softmax(predictions[0])\n",
    "# #print(predictions)\n",
    "# print(\n",
    "#     \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "#     .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "# )\n",
    "# #print(paths[-1])\n",
    "# #PIL.Image.open(paths[-1])\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i in range(15):\n",
    "#     ax = plt.subplot(5, 3, i + 1)\n",
    "#     plt.imshow(images[i].astype(\"uint8\"))\n",
    "# #     predictions = model.predict(image[i])\n",
    "# #     score = tf.nn.softmax(predictions[0])\n",
    "# #     plt.title(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "#     plt.title(class_names[classes[i]])\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #overcast 20191030T161529_VOOR\n",
    "\n",
    "# #rain 20161013T164513_YORK.jpg_sliding_window.jpg\n",
    "\n",
    "# #partly 20191112T183029_VOOR\n",
    "\n",
    "# #clear 20190511T122529_VOOR\n",
    "# #clear 20191008T165026_BURT\n",
    "# #clear 20160420T221001_DELE\n",
    "# new_img_path = '/home/mesonet/cam_photos/2018/12/20/VOOR/20181220T175030_VOOR.jpg'\n",
    "# #new_img_path = '/home/arnold/raindrop-detection-cnn/mesonet/20161013T164513_YORK.jpg_sliding_window.jpg'\n",
    "\n",
    "# img = keras.preprocessing.image.load_img(\n",
    "#     new_img_path, target_size=(img_height, img_width)\n",
    "# )\n",
    "\n",
    "# # height, width, channels = img.shape\n",
    "# # print(int(height/3))\n",
    "# # croppedImage = img[0:int(height/3), 0:width] #this line crops\n",
    "\n",
    "# img_array = keras.preprocessing.image.img_to_array(img)\n",
    "# img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "# predictions = model.predict(img_array)\n",
    "# score = tf.nn.softmax(predictions[0])\n",
    "# print(predictions)\n",
    "# print(\n",
    "#     \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "#     .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "# )\n",
    "# PIL.Image.open(new_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_ds.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Working for testing a full dataset \n",
    "#Retrieve a batch of images from the test set\n",
    "#replace val_ds with test_ds\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  plt.title(class_names[predictions[i]])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
