{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains all the main external libs we'll use\n",
    "from fastai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.backends.cudnn.enabled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overcast 20191030T161529_VOOR\n",
    "#partly 20191112T183029_VOOR\n",
    "#clear 20190511T122529_VOOR\n",
    "PATH = '/home/arnold/raindrop-detection-cnn/ALL'\n",
    "data_dir = pathlib.Path(PATH)\n",
    "#resize image \n",
    "sz=224\n",
    "# List containing the entries in the directory given by PATH\n",
    "os.listdir(PATH)\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rains = list(data_dir.glob('rain/*'))\n",
    "# PIL.Image.open(str(roses[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(f'{PATH}/clear')[:10]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(f'{PATH}/clear/{files[9]}')\n",
    "plt.imshow(img);\n",
    "img.shape\n",
    "# First 4 rows and columns of the image\n",
    "#img[:4,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dirs(path, folder):\n",
    "    labels, filenames, all_labels = [], [], []\n",
    "    full_path = os.path.join(path, folder)\n",
    "    for label in sorted(os.listdir(full_path)):\n",
    "        if label not in ('.ipynb_checkpoints'):\n",
    "            all_labels.append(label)\n",
    "            for fname in os.listdir(os.path.join(full_path, label)):\n",
    "                filenames.append(os.path.join(folder, label, fname))\n",
    "                labels.append(label)\n",
    "    return filenames, labels, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 720\n",
    "img_width = 1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run rm -rf .ipynb_checkpoints to get correct class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor of shape (bathsize, hgt, width, rgb)\n",
    "#call .numpy() on the image_batch and labels_batch tensors to convert them to a numpy.ndarray\n",
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE\n",
    "'''\n",
    "Dataset.cache() keeps the images in memory after they're loaded off disk during the first epoch. \n",
    "This will ensure the dataset does not become a bottleneck while training your model. \n",
    "If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\n",
    "\n",
    "Dataset.prefetch() overlaps data preprocessing and model execution while training.\n",
    "'''\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RGB channel values are in the [0, 255] range. Bad for neural network; want input values small. \n",
    "#Standardize values to be in the [0, 1] by using a Rescaling layer.\n",
    "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixels values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = 7\n",
    "# #build the model\n",
    "# model = Sequential([\n",
    "#   layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "#   layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "#   layers.MaxPooling2D(),\n",
    "#   layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "#   layers.MaxPooling2D(),\n",
    "#   layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#   layers.MaxPooling2D(),\n",
    "#   layers.Flatten(),\n",
    "#   layers.Dense(128, activation='relu'),\n",
    "#   layers.Dense(num_classes)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #compile the model (To view training and validation accuracy for each training epoch, pass the metrics argument)\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #View all the layers of the network using the model's summary method:\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train the model\n",
    "# epochs=40\n",
    "# history = model.fit(\n",
    "#   train_ds,\n",
    "#   validation_data=val_ds,\n",
    "#   epochs=epochs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #visualize training results\n",
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "\n",
    "# loss=history.history['loss']\n",
    "# val_loss=history.history['val_loss']\n",
    "\n",
    "# epochs_range = range(epochs)\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "# plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(epochs_range, loss, label='Training Loss')\n",
    "# plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.show()\n",
    "\n",
    "# '''\n",
    "# NOTE\n",
    "# if training accuracy and validation accuracy are off by large margin then need to tune the model and its overfitting\n",
    "# overfitting if diiff in acc between training and val accuracy is noticeable\n",
    "# also if training acc inc linearly but val acc stalls around 50-60%\n",
    "\n",
    "# FIX:\n",
    "# 'When there are a small number of training examples, the model sometimes learns from noises or unwanted details from training examples—to an extent that it negatively impacts the performance of the model on new examples. This phenomenon is known as overfitting. It means that the model will have a difficult time generalizing on a new dataset.\n",
    "\n",
    "# There are multiple ways to fight overfitting in the training process. In this tutorial, you'll use data augmentation and add Dropout to your model.'\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save the model\n",
    "# model.save(\"/home/arnold/raindrop-detection-cnn/models/custom_cloud_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data augmentation - generating additional training data from your existing examples by augmenting then using random transformations that yield believable-looking images\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
    "                                                 input_shape=(img_height, \n",
    "                                                              img_width,\n",
    "                                                              3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "#     layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #viz augmented images\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, _ in train_ds.take(1):\n",
    "#   for i in range(9):\n",
    "#     augmented_images = data_augmentation(images)\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.\n",
    "num_classes = 7\n",
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overcast 20191030T161529_VOOR\n",
    "\n",
    "#rain 20161013T164513_YORK.jpg_sliding_window.jpg\n",
    "\n",
    "#partly 20191112T183029_VOOR\n",
    "\n",
    "#clear 20190511T122529_VOOR\n",
    "#clear 20191008T165026_BURT\n",
    "#clear 20160420T221001_DELE\n",
    "new_img_path = '/home/mesonet/cam_photos/2018/12/20/VOOR/20181220T175030_VOOR.jpg'\n",
    "#new_img_path = '/home/arnold/raindrop-detection-cnn/mesonet/20161013T164513_YORK.jpg_sliding_window.jpg'\n",
    "\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    new_img_path, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "print(predictions)\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n",
    "PIL.Image.open(new_img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/home/arnold/raindrop-detection-cnn/models/custom_cloud_classification_augmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/home/mesonet/cam_photos/2018/06/17/VOOR'\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# load all images into a list\n",
    "paths = []\n",
    "images = []\n",
    "for img in os.listdir(folder_path):\n",
    "    img = os.path.join(folder_path, img)\n",
    "    paths.append(img)\n",
    "    img = image.load_img(img, target_size=(img_height, img_width))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    images.append(img)\n",
    "# print(images[1])\n",
    "# stack up images list to pass for prediction\n",
    "images = np.vstack(images)\n",
    "#print(paths)\n",
    "# for i in paths:\n",
    "#     PIL.Image.open(i)\n",
    "#\n",
    "\n",
    "classes = model.predict_classes(images, batch_size=32)\n",
    "print(class_names)\n",
    "print(classes)\n",
    "predictions = model.predict(images)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "#print(predictions)\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n",
    "#print(paths[-1])\n",
    "#PIL.Image.open(paths[-1])\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(15):\n",
    "    ax = plt.subplot(5, 3, i + 1)\n",
    "    plt.imshow(images[i].astype(\"uint8\"))\n",
    "#     predictions = model.predict(image[i])\n",
    "#     score = tf.nn.softmax(predictions[0])\n",
    "#     plt.title(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "    plt.title(class_names[classes[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will select all the file names and put them in a list (from all children sub dirs)\n",
    "def getListOfFiles(dirName):\n",
    "    # create a list of file and sub directories \n",
    "    # names in the given directory \n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        # If entry is a directory then get the list of files in this directory \n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "                \n",
    "    return allFiles    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4597\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "listOfFiles = glob.glob('/home/mesonet/cam_photos/2017/12/*/VOOR/*')\n",
    "print(len(listOfFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all images into a list\n",
    "paths_all = []\n",
    "images_all = []\n",
    "for img in listOfFiles:\n",
    "#     img = os.path.join(folder_path, img)\n",
    "#     print(img)\n",
    "    paths_all.append(img)\n",
    "    img = image.load_img(img, target_size=(img_height, img_width))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    images_all.append(img)\n",
    "# print(images_all[1])    \n",
    "images_all = np.vstack(images_all)\n",
    "\n",
    "classes = model.predict_classes(images_all, batch_size=64)\n",
    "print(class_names)\n",
    "print(classes)\n",
    "\n",
    "#save predicted images to folders\n",
    "#['clear', 'few', 'night', 'overcast', 'rain', 'scattered', 'snow']\n",
    "print(len(classes))\n",
    "\n",
    "r =0\n",
    "for k,i in enumerate(classes):\n",
    "    if i==0:\n",
    "        #save image\n",
    "#         print(paths_all[k][-24:])\n",
    "        im = PIL.Image.fromarray(images_all[k].astype(\"uint8\"))\n",
    "        im.save(\"/home/arnold/raindrop-detection-cnn/ALL/clear/\"+paths_all[k][-24:])\n",
    "    elif i==1:\n",
    "#         print(paths_all[k])\n",
    "        im = PIL.Image.fromarray(images_all[k].astype(\"uint8\"))\n",
    "        im.save(\"/home/arnold/raindrop-detection-cnn/ALL/few/\"+paths_all[k][-24:])\n",
    "    elif i==2:\n",
    "#         print(paths_all[k])\n",
    "        im = PIL.Image.fromarray(images_all[k].astype(\"uint8\"))\n",
    "        im.save(\"/home/arnold/raindrop-detection-cnn/ALL/night/\"+paths_all[k][-24:])\n",
    "    elif i==3:\n",
    "#         print(paths_all[k])\n",
    "        im = PIL.Image.fromarray(images_all[k].astype(\"uint8\"))\n",
    "        im.save(\"/home/arnold/raindrop-detection-cnn/ALL/overcast/\"+paths_all[k][-24:])    \n",
    "    elif i==4:\n",
    "#         print(paths_all[k])\n",
    "        im = PIL.Image.fromarray(images_all[k].astype(\"uint8\"))\n",
    "        im.save(\"/home/arnold/raindrop-detection-cnn/ALL/rain/\"+paths_all[k][-24:])\n",
    "    elif i==5:\n",
    "#         print(paths_all[k])\n",
    "        im = PIL.Image.fromarray(images_all[k].astype(\"uint8\"))\n",
    "        im.save(\"/home/arnold/raindrop-detection-cnn/ALL/scattered/\"+paths_all[k][-24:])\n",
    "    elif i==6:\n",
    "#         print(paths_all[k])\n",
    "        im = PIL.Image.fromarray(images_all[k].astype(\"uint8\"))\n",
    "        im.save(\"/home/arnold/raindrop-detection-cnn/ALL/snow/\"+paths_all[k][-24:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(15):\n",
    "    ax = plt.subplot(5, 3, i + 1)\n",
    "    plt.imshow(images_all[i].astype(\"uint8\"))\n",
    "#     predictions = model.predict(image[i])\n",
    "#     score = tf.nn.softmax(predictions[0])\n",
    "#     plt.title(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "    plt.title(class_names[classes[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save predicted images to folders\n",
    "# #['clear', 'few', 'night', 'overcast', 'rain', 'scattered', 'snow']\n",
    "# print(len(classes))\n",
    "\n",
    "# r =0\n",
    "# for k,i in enumerate(classes):\n",
    "#     if i==4:\n",
    "#         #save image\n",
    "#         print(paths_all[k][-24:])\n",
    "# #         im = PIL.Image.fromarray(images_all[k].astype(\"uint8\"))\n",
    "# #         im.save(\"/home/arnold/raindrop-detection-cnn/VOOR/rain/\"+paths_all[k][-24:])\n",
    "#     elif i==6:\n",
    "#         print(paths_all[k])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (class_names)\n",
    "j=0\n",
    "rain_imgs = []\n",
    "plt.figure(figsize=(10, 9))\n",
    "for k,i in enumerate(classes):\n",
    "#     print(k,i)\n",
    "    if i==6:\n",
    "        j += 1\n",
    "        rain_imgs.append(images_all[k])\n",
    "#         plt.subplot(3,4,i+1)\n",
    "#         plt.imshow(images_all[k].astype(\"uint8\"))\n",
    "#         plt.title(class_names[i])\n",
    "#         plt.axis('off')\n",
    "#         print(j)\n",
    "#         print(class_names[i])\n",
    "#         plt.imshow(images_all[i].astype(\"uint8\"))\n",
    "# print(rain_imgs)\n",
    "print(j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 9))\n",
    "# print((rain_imgs[1]))\n",
    "# plt.imshow(rain_imgs[1].astype(\"uint8\"))\n",
    "# plt.imshow(rain_imgs[2].astype(\"uint8\"))\n",
    "\n",
    "\n",
    "\n",
    "for i in range(11):\n",
    "    plt.subplot(4,3,i+1)\n",
    "    plt.imshow(rain_imgs[i].astype(\"uint8\"))\n",
    "#     plt.title(class_names[i])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model_predictions = model.predict(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_model_predictions.shape) #“Prediction results shape:”, (219, 7)\n",
    "predicted_ids = np.argmax(tf_model_predictions, axis=-1)\n",
    "# predicted_labels = class_names[predicted_ids]\n",
    "print(predicted_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for n in range(36): #predicted_labels\n",
    "    plt.subplot(6,6,n+1)\n",
    "    plt.imshow(images[n].astype(\"uint8\"))\n",
    "#     color = \"green\" if predicted_ids[n] == true_label_ids[n] else \"red\"\n",
    "    plt.title(class_names[predicted_ids[n]]) #predicted_labels\n",
    "    plt.axis('off')\n",
    "#     _ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
