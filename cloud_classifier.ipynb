{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the package we'll use\n",
    "from fastai.imports import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to make sure you have access to a GPU\n",
    "# torch.cuda.is_available()\n",
    "# torch.backends.cudnn.enabled\n",
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change below path to /tf/username/model_img/ESSX\n",
    "PATH = '/raid/arnold/clouds_detection/ESSX'\n",
    "data_dir = pathlib.Path(PATH)\n",
    "#resize image \n",
    "# sz=224\n",
    "# List containing the entries in the directory given by PATH\n",
    "os.listdir(PATH)\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "\n",
    "#set batch size and original image dimensions\n",
    "batch_size = 32\n",
    "img_height = 720\n",
    "img_width = 1280\n",
    "\n",
    "#total image count\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do a quick check and make sure you have image data\n",
    "files = os.listdir(f'{PATH}/clear')[:10]\n",
    "img = plt.imread(f'{PATH}/clear/{files[9]}')\n",
    "plt.imshow(img);\n",
    "print(img.shape)\n",
    "# First 4 rows and columns of the image\n",
    "img[:4,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if using croping uncomment this section and comment out below code where i indicated\n",
    "# #cropping top of image \n",
    "# height, width, channels = img.shape\n",
    "# print(int(height/3))\n",
    "# croppedImage = img[0:int(height/3), 0:width] #this line crops\n",
    "# # croppedImage = img[0:360, 0:width] #this line crops\n",
    "\n",
    "# plt.imshow(croppedImage);\n",
    "# croppedImage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #cropping center\n",
    "# image = tf.image.resize_with_crop_or_pad(img, 240, 1280) \n",
    "# image = tf.image.random_crop(image, size=[240, 1280, 3])\n",
    "# plt.imshow(image);\n",
    "# image.shape\n",
    "# # Random crop back to the original size\n",
    "# #   image = tf.image.random_crop(image, size=[IMG_SIZE, IMG_SIZE, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape = (1,720, 1280, 3)\n",
    "# print(input_shape)\n",
    "# x = np.arange(np.prod(input_shape)).reshape(input_shape)\n",
    "# y = tf.keras.layers.Cropping2D(cropping=((2, 2), (4, 4)))(x)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #WORKS to crop multi images now need to save them for a model\n",
    "\n",
    "# folder_path = '/home/mesonet/cam_photos/2018/08/17/ESSX'\n",
    "# from keras.preprocessing import image\n",
    "\n",
    "# # load all images into a list\n",
    "# paths = []\n",
    "# images = []\n",
    "# for img in os.listdir(folder_path):\n",
    "#     img = os.path.join(folder_path, img)\n",
    "#     paths.append(img)\n",
    "#     img = image.load_img(img, target_size=(img_height, img_width))\n",
    "#     img = image.img_to_array(img)\n",
    "#     img = img[0:int(height/3), 0:width]\n",
    "#     img = np.expand_dims(img, axis=0)\n",
    "#     images.append(img)\n",
    "# # print(images[1])\n",
    "# # stack up images list to pass for prediction\n",
    "# images = np.vstack(images)\n",
    "\n",
    "# #print(paths[-1])\n",
    "# #PIL.Image.open(paths[-1])\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i in range(15):\n",
    "#     ax = plt.subplot(5, 3, i + 1)\n",
    "#     plt.imshow(images[i].astype(\"uint8\"))\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dirs(path, folder):\n",
    "    labels, filenames, all_labels = [], [], []\n",
    "    full_path = os.path.join(path, folder)\n",
    "    for label in sorted(os.listdir(full_path)):\n",
    "        if label not in ('.ipynb_checkpoints'):\n",
    "            all_labels.append(label)\n",
    "            for fname in os.listdir(os.path.join(full_path, label)):\n",
    "                filenames.append(os.path.join(folder, label, fname))\n",
    "                labels.append(label)\n",
    "    return filenames, labels, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run rm -rf .ipynb_checkpoints to get correct class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below if not cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look under fine tune in https://www.tensorflow.org/tutorials/load_data/images to add cropping into pipeline myself\n",
    "#take 80% for training and pass 20% in next cell for validation\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #use this manual method if cropping being applied or above if not cropping\n",
    "# list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle=False)\n",
    "# list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n",
    "# for f in list_ds.take(5):\n",
    "#   print(f.numpy())\n",
    "\n",
    "# class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
    "# print(class_names)\n",
    "# #split into training and val \n",
    "# val_size = int(image_count * 0.2)\n",
    "# train_ds = list_ds.skip(val_size)\n",
    "# val_ds = list_ds.take(val_size)\n",
    "\n",
    "# print(tf.data.experimental.cardinality(train_ds).numpy())\n",
    "# print(tf.data.experimental.cardinality(val_ds).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_label(file_path):\n",
    "#   # convert the path to a list of path components\n",
    "#     parts = tf.strings.split(file_path, os.path.sep)\n",
    "#   # The second to last is the class-directory\n",
    "#     one_hot = parts[-2] == class_names\n",
    "#   # Integer encode the label\n",
    "#     return tf.argmax(one_hot)\n",
    "\n",
    "# def decode_img(img):\n",
    "#   # convert the compressed string to a 3D uint8 tensor\n",
    "#     img = tf.image.decode_jpeg(img, channels=3)\n",
    "#   # resize the image to the desired size\n",
    "#     return tf.image.resize(img, [img_height, img_width])\n",
    "\n",
    "\n",
    "# def process_path(file_path):\n",
    "#     label = get_label(file_path)\n",
    "#   # load the raw data from the file as a string\n",
    "#     img = tf.io.read_file(file_path)\n",
    "#     img = decode_img(img)\n",
    "# #     img = image.img_to_array(img)\n",
    "#     height, width, channels = img.shape\n",
    "# #     img = img[0:int(height/3), 0:width] #1/3 top \n",
    "#     img = img[0:int(height/2), 0:width] #half\n",
    "#     print(img.shape)\n",
    "#     return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "# val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# for image, label in train_ds.take(1):\n",
    "#   print(\"Image shape: \", image.numpy().shape)\n",
    "#   print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def configure_for_performance(ds):\n",
    "#     ds = ds.cache()\n",
    "#     ds = ds.shuffle(buffer_size=1000)\n",
    "#     ds = ds.batch(batch_size)\n",
    "#     ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "#     return ds\n",
    "\n",
    "# train_ds = configure_for_performance(train_ds)\n",
    "# val_ds = configure_for_performance(val_ds)\n",
    "\n",
    "# image_batch, label_batch = next(iter(train_ds))\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i in range(9):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "#     label = label_batch[i]\n",
    "#     plt.title(class_names[label])\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#   train_ds,\n",
    "#   validation_data=val_ds,\n",
    "#   epochs=3\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment out if doing cropping\n",
    "class_names = train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check classs names to make sure you dont have any hidden folders and img dims are correct\n",
    "print(class_names)\n",
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display a few images for a sanity check (all labels should be correct, and no imgs should be corrupted)\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor of shape (batch size, hgt, width, rgb)\n",
    "#call .numpy() on the image_batch and labels_batch tensors to convert them to a numpy.ndarray\n",
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE\n",
    "'''\n",
    "Dataset.cache() keeps the images in memory after they're loaded off disk during the first epoch. \n",
    "This will ensure the dataset does not become a bottleneck while training your model. \n",
    "If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\n",
    "\n",
    "Dataset.prefetch() overlaps data preprocessing and model execution while training.\n",
    "\n",
    "Dont forget to clear notebook and shut down kernel when done, otherwise gpu memory will not be released\n",
    "'''\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RGB channel values are in the [0, 255] range. Bad for neural network; want input values small. \n",
    "#Standardize values to be in the [0, 1] by using a Rescaling layer.\n",
    "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply normalization layer to full dataset\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixels values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names) #if you get error you  prob need to delete .ipyn checkpoint\n",
    "#build the model\n",
    "model = Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),  #rescale input in the [0, 255] range to be in the [0, 1] range\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.1),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model (To view training and validation accuracy for each training epoch, pass the metrics argument)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View all the layers of the network using the model's summary method:\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "epochs=3 #if you want to do quick test run change this to 1 or 2\n",
    "history = model.fit(\n",
    "  normalized_ds,\n",
    "  validation_data=normalized_val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "NOTE\n",
    "if training accuracy and validation accuracy are off by large margin then need to tune the model and its overfitting\n",
    "overfitting if diiff in acc between training and val accuracy is noticeable\n",
    "also if training acc inc linearly but val acc stalls around 50-60%\n",
    "\n",
    "FIX:\n",
    "'When there are a small number of training examples, the model sometimes learns from noises or unwanted details from training sometimes referred to as overfitting. It means that the model will have a difficult time generalizing on a new dataset.\n",
    "\n",
    "There are multiple ways to stop overfitting in the training process. We will use two differnet ways below. First by creating more images using data augmentation and second adding a Dropout layer to the model.'\n",
    "'''\n",
    "#visualize training results\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save the model\n",
    "# model.save(\"/raid/arnold/clouds_detection/model/custom_cloud_classification_test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "# It can be used to reconstruct the model identically and i am going to load this model i ran overnight to save time.\n",
    "# model = keras.models.load_model(\"/raid/arnold/clouds_detection/model/custom_cloud_classification/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data augmentation - generating additional training data from your existing examples by augmenting then using transformations that yield believable-looking images\n",
    "#below i have examples of random cropping, flipping, rotations and zoom. \n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "#       tf.keras.layers.experimental.preprocessing.RandomCrop(\n",
    "#     240, 1280\n",
    "# )\n",
    "#     layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
    "#                                                  input_shape=(img_height, \n",
    "#                                                               img_width,\n",
    "#                                                               3)),\n",
    "#     layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_augmentation(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viz some of the augmented images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.\n",
    "print(len(class_names))\n",
    "num_classes = len(class_names)\n",
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "history = model.fit(\n",
    "  normalized_ds,\n",
    "  validation_data=normalized_val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img_path =  '/raid/mesonet/cam_photos/2018/12/20/VOOR/20181220T175030_VOOR.jpg'\n",
    "#new_img_path = '/home/arnold/raindrop-detection-cnn/mesonet/20161013T164513_YORK.jpg_sliding_window.jpg'\n",
    "\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    new_img_path, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "print(predictions)\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n",
    "PIL.Image.open(new_img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to save augmented model\n",
    "# model.save(\"/raid/arnold/clouds_detection/models/custom_cloud_classification_augmented_3_sites\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "# It can be used to reconstruct the model identically and i am going to load this model i ran overnight to save time.\n",
    "# model = keras.models.load_model(\"/raid/arnold/clouds_detection/models/custom_cloud_classification_augmented_3_sites\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model_predictions = model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_model_predictions.shape) #“Prediction results shape:”, (219, 7)\n",
    "predicted_ids = np.argmax(tf_model_predictions, axis=-1)\n",
    "# predicted_labels = class_names[predicted_ids]\n",
    "print(predicted_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
