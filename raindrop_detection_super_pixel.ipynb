{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/py3.4/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/anaconda3/envs/py3.4/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/anaconda3/envs/py3.4/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/anaconda3/envs/py3.4/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/anaconda3/envs/py3.4/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/anaconda3/envs/py3.4/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)\n",
      "Scipy not supported!\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "\n",
    "# Example : Detect raindrops within an image by using super pixel algorithm\n",
    "# and classify the ROI by using AlexNet CNN.\n",
    "\n",
    "# Copyright (c) 2017/18 - Tiancheng Guo / Toby Breckon, Durham University, UK\n",
    "\n",
    "# License : https://github.com/GTC7788/raindropDetection/blob/master/LICENSE\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# The green rectangles represents the detected raindrops.\n",
    "# the red rectangles represents the ground truth raindrops in that image.\n",
    "\n",
    "# This script takes 1 argument indicating the image to process.\n",
    "# e.g.\n",
    "# > python raindrop_detection_super_pixel.py 3\n",
    "# will process image 3 in the raindrop_detection_images folder and use\n",
    "# the associated ground truth xml file  in ground_truth_labels folder\n",
    "# for image 3 as well.\n",
    "\n",
    "# This program will output 2 images in the current folder, one is the\n",
    "# detection result, one is the super pixel segmentation result.\n",
    "################################################################################\n",
    "\n",
    "from __future__ import division, print_function, absolute_import\n",
    "import numpy as np\n",
    "import tflearn\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import xml.etree.ElementTree as ET\n",
    "from math import sqrt\n",
    "from PIL import Image\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_utils import build_image_dataset_from_dir\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "\n",
    "# Use a command line parser to read command line argument\n",
    "# The integer number represents the number of the image to process\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('integers', metavar='N', type=int, nargs='+',\n",
    "#                    help='an integer represents the number of image')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "#number = args.integers[0]\n",
    "\n",
    "# Manually set the number of image to process.\n",
    "number = 2\n",
    "\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# Image path\n",
    "# image_path = \"raindrop_detection_images/%s.jpg\" % number\n",
    "#/home/arnold/raindrop-detection-cnn/dataset/detection/image\n",
    "image_path = \"/home/arnold/raindrop-detection-cnn/mesonet/20191008T165026_BURT.jpg\" \n",
    "\n",
    "# Path to output the result image after raindrop detection\n",
    "result_path = \"/home/arnold/raindrop-detection-cnn/img_%s_super_pixel_result.jpg\" % number\n",
    "\n",
    "# Path to the xml file that contains the ground truth data\n",
    "# ground_truth_xml_path = \"ground_truth_labels/%s.xml\" % number\n",
    "ground_truth_xml_path = \"/home/arnold/raindrop-detection-cnn/dataset/detection/ground-truth-label/ground-truth-00003.xml\" \n",
    "\n",
    "# Path of the trained model for AlexNet\n",
    "# model_path = 'Model/alexRainApr06.tfl'\n",
    "model_path = 'models/alexnet_30_2_detection.tfl'\n",
    "\n",
    "# Turn on ground truth detections on image\n",
    "ground_truth = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Convert the PIL Image object into array.\n",
    "Args:\n",
    "\tpil_image: PIL image object\n",
    "Returns:\n",
    "\tresult: an array ready for the CNN to predict\n",
    "\"\"\"\n",
    "def img_to_array(pil_image):\n",
    "\n",
    "    pil_image.load()\n",
    "    result = np.asarray(pil_image, dtype=\"float32\")\n",
    "    result /= 255\n",
    "    return result\n",
    "\n",
    "################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Set up the structure of AlexNet-30^2 CNN by using TFLearn.\n",
    "Returns:\n",
    "\tnetwork: a CNN which follows the structure of AlexNet.\n",
    "\"\"\"\n",
    "def create_basic_alexnet():\n",
    "\n",
    "\t# Building network as per architecture in [Guo/Breckon, 2018]\n",
    "\n",
    "\tnetwork = input_data(shape=[None, 30, 30, 3])\n",
    "\tnetwork = conv_2d(network, 64, 11, strides=4, activation='relu')\n",
    "\tnetwork = max_pool_2d(network, 3, strides=2)\n",
    "\tnetwork = local_response_normalization(network)\n",
    "\tnetwork = conv_2d(network, 128, 5, activation='relu')\n",
    "\tnetwork = max_pool_2d(network, 3, strides=2)\n",
    "\tnetwork = local_response_normalization(network)\n",
    "\tnetwork = conv_2d(network, 256, 3, activation='relu')\n",
    "\tnetwork = conv_2d(network, 256, 3, activation='relu')\n",
    "\tnetwork = conv_2d(network, 128, 3, activation='relu')\n",
    "\tnetwork = max_pool_2d(network, 3, strides=2)\n",
    "\tnetwork = local_response_normalization(network)\n",
    "\tnetwork = fully_connected(network, 4096, activation='tanh')\n",
    "\tnetwork = dropout(network, 0.5)\n",
    "\tnetwork = fully_connected(network, 4096, activation='tanh')\n",
    "\tnetwork = dropout(network, 0.5)\n",
    "\tnetwork = fully_connected(network, 2, activation='softmax')\n",
    "\tnetwork = regression(network, optimizer='momentum',\n",
    "\t                     loss='categorical_crossentropy',\n",
    "\t                     learning_rate=0.001)\n",
    "\treturn network\n",
    "\n",
    "\n",
    "################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Calculates all the windows that will slide through an image.\n",
    "\n",
    "Args:\n",
    "\timage: the image to apply sliding window.\n",
    "\tstepSize: step size (in pixel) between each window.\n",
    "\twindowSize: size of each window.\n",
    "Return:\n",
    "\tAll of the sliding windows for an image, each element represents\n",
    "\tthe coordinates of top left corner of the window and its size.\n",
    "\"\"\"\n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "\t# slide a window across the image\n",
    "\tfor y in range(0, image.shape[0], stepSize):\n",
    "\t\tfor x in range(0, image.shape[1], stepSize):\n",
    "\t\t\t# yield the current window\n",
    "\t\t\tyield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\n",
    "\n",
    "################################################################################\n",
    "\n",
    "\"\"\"\n",
    "This method uses the openCV built in function to perform the super pixel algorithm\n",
    "to an image. When the image is segmented into small pieces, stretch each irregular\n",
    "shape into 30 x 30 rectangles.\n",
    "\n",
    "Those rectangles will be region of interests and will be classified by the AlexNet.\n",
    "\n",
    "Args:\n",
    "\timage: the image to process\n",
    "Return:\n",
    "\tlist of detected raindrop coordinates\n",
    "\"\"\"\n",
    "def super_pixel(image):\n",
    "\n",
    "\trectangle_result = []\n",
    "\n",
    "\tseeds = None\n",
    "\tdisplay_mode = 0\n",
    "\n",
    "\t# ******** Super pixel parameters **********\n",
    "\tnum_superpixels = 1000\n",
    "\tprior = 5\n",
    "\tnum_levels = 1\n",
    "\tnum_iterations = 5\n",
    "\tnum_histogram_bins = 5\n",
    "\t# ******************************************\n",
    "\n",
    "\tconverted_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\theight,width,channels = converted_img.shape\n",
    "\n",
    "\t# Use the built in function to perform super pixel algorithm on the image\n",
    "\tseeds = cv2.ximgproc.createSuperpixelSEEDS(width, height, channels,\n",
    "\t    num_superpixels, num_levels, prior, num_histogram_bins)\n",
    "\n",
    "\tseeds.iterate(converted_img, num_iterations)\n",
    "\tcolor_img = np.zeros((height,width,3), np.uint8)\n",
    "\tcolor_img[:] = (0, 0, 255)\n",
    "\tnumber_of_super = seeds.getNumberOfSuperpixels()\n",
    "\n",
    "\tlabels = seeds.getLabels()\n",
    "\tmask = seeds.getLabelContourMask(False)\n",
    "\tmask_inv = cv2.bitwise_not(mask)\n",
    "\tresult_bg = cv2.bitwise_and(image, image, mask=mask_inv)\n",
    "\tresult_fg = cv2.bitwise_and(color_img, color_img, mask=mask)\n",
    "\tresult = cv2.add(result_bg, result_fg)\n",
    "\tcv2.imwrite('img_%s_super_pixel_segmentation.jpg' %number, result)\n",
    "\n",
    "\n",
    "\t# For each 'super pixel', as the shape is an irregular and couldn't pass\n",
    "\t# into TensorFlow, we have to stretch the image into a regular rectangle.\n",
    "\tfor i in range(number_of_super):\n",
    "\t    result = np.where( labels == i )\n",
    "\t    resultT = np.asarray(result).T\n",
    "\n",
    "\t    smallestX = 99999\n",
    "\t    smallestY = 99999\n",
    "\t    biggestX = 0\n",
    "\t    biggestY = 0\n",
    "\t    for element in resultT:\n",
    "\t        if element[0] < smallestY:\n",
    "\t            smallestY = element[0]\n",
    "\t        if element[0] > biggestY:\n",
    "\t            biggestY = element[0]\n",
    "\t        if element[1] < smallestX:\n",
    "\t            smallestX = element[1]\n",
    "\t        if element[1] > biggestX:\n",
    "\t            biggestX = element[1]\n",
    "\t    roi = image[smallestY:biggestY, smallestX:biggestX]\n",
    "\n",
    "\t    if roi.shape[0] != 0 and roi.shape[1] != 0 :\n",
    "\t    \tnew_roi = cv2.resize(roi,(30,30))\n",
    "\t    \tim = Image.fromarray(new_roi)\n",
    "\t    \ttensor_image = img_to_array(im)\n",
    "\t    \timgs = []\n",
    "\t    \timgs.append(tensor_image)\n",
    "\n",
    "\t    \t# classify the region of interest\n",
    "\t    \tpredict_result = model.predict(imgs)\n",
    "\t    \tfinal_result = np.argmax(predict_result[0])\n",
    "\t\t\t# if it is a raindrop, add to result list\n",
    "\t    \tif final_result == 1:\n",
    "\t    \t\trectangle_result.append((smallestX, smallestY,\n",
    "\t    \t\t\tbiggestX, biggestY))\n",
    "\treturn rectangle_result\n",
    "\n",
    "\n",
    "################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Sliding window algorithm will generates too many rectangles.\n",
    "We can use the groupRectangles method to reduce overlapping rectangles.\n",
    "Args:\n",
    "\trectangleList_before: list of detected regions (rectangles).\n",
    "\tthreshold: Minimum possible number of rectangles minus 1.\n",
    "\t\t\t   The threshold is used in a group of rectangles to retain it.\n",
    "\teps: Relative difference between sides of the rectangles to merge them into a group.\n",
    "Return:\n",
    "\trectangleList_after: list of optimized detected regions.\n",
    "\"\"\"\n",
    "# Regularise the format of the proposed result list.\n",
    "def utilize_rectangle_list(rectangleList_before, threshold, eps):\n",
    "\t# Using the groupRectangles() function to shrink the rectangle list\n",
    "\trectangleList_after = []\n",
    "\n",
    "\tfor element in rectangleList_before:\n",
    "\t\tfull_rectangle_list = []\n",
    "\t\tfull_rectangle_list.append(element[0])\n",
    "\t\tfull_rectangle_list.append(element[1])\n",
    "\t\tfull_rectangle_list.append(element[0]+30)\n",
    "\t\tfull_rectangle_list.append(element[1]+30)\n",
    "\t\trectangleList_after.append(full_rectangle_list)\n",
    "\n",
    "\t# group the proposed overlapping regions into one region,\n",
    "\t# decrese the recall but increase the precision.\n",
    "\trectangleList_after, weight = cv2.groupRectangles(rectangleList_after, threshold, eps)\n",
    "\n",
    "\treturn rectangleList_after\n",
    "\n",
    "################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Parse the xml file that stores the ground truth raindrop locations in the image\n",
    "\n",
    "Args:\n",
    "\tfileName: the xml file name\n",
    "Returns:\n",
    "\tlist that each element contains the location of a ground truth raindrop\n",
    "\n",
    "\"\"\"\n",
    "def parse_xml_file(fileName):\n",
    "\txml_file = ET.parse(fileName)\n",
    "\t# XML_path to retrieve the x, y coordinates\n",
    "\txIndex = xml_file.findall('object/polygon/pt/x')\n",
    "\tyIndex = xml_file.findall('object/polygon/pt/y')\n",
    "\txList = []\n",
    "\tyList = []\n",
    "\tfor x in xIndex:\n",
    "\t\txList.append(int(x.text))\n",
    "\n",
    "\tfor y in yIndex:\n",
    "\t\tyList.append(int(y.text))\n",
    "\n",
    "\tcombinedList = zip(xList,yList)\n",
    "\n",
    "\tsubList = []\n",
    "\tfinalList = []\n",
    "\tcounter = 1\n",
    "\tfor element in combinedList:\n",
    "\t\tswitch = counter % 4\n",
    "\t\tif switch == 0:\n",
    "\t\t\tsubList.append(element)\n",
    "\t\t\tfinalList.append(subList)\n",
    "\t\t\tsubList = []\n",
    "\t\telse:\n",
    "\t\t\tsubList.append(element)\n",
    "\t\tcounter += 1\n",
    "\n",
    "\treturn finalList\n",
    "\n",
    "################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Retrieve the coordinates of each ground truth raindrop locations\n",
    "Args:\n",
    "\txml_golden: a list that each element contains the location of a ground truth raindrop\n",
    "Returns:\n",
    "\ta list of coordinates for each ground truth raindrops that ready for drawing.\n",
    "\"\"\"\n",
    "def xml_transform(xml_golden):\n",
    "\txml_result = []\n",
    "\tfor element in xml_golden:\n",
    "\t\tsub_list = []\n",
    "\t\tsub_list = [element[0][0], element[0][1],\n",
    "\t\telement[2][0], element[2][1]]\n",
    "\n",
    "\t\txml_result.append(sub_list)\n",
    "\treturn xml_result\n",
    "\n",
    "\n",
    "################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Slide the window across the image, pass each window (region of interest) into the trained AlexNet.\n",
    "If the region is classified as a raindrop, store the region's coordinates in a list and return\n",
    "the list.\n",
    "\n",
    "Args:\n",
    "\timage: the image to process\n",
    "\twinW: width of the sliding window\n",
    "\twinH: height of the sliding window\n",
    "Return:\n",
    "\trectangle_result: a list of region of interest that classified as raindrop by the AlexNet\n",
    "\"\"\"\n",
    "def cnn_find_raindrop(image, winW, winH):\n",
    "\trectangle_result = []\n",
    "\n",
    "\tfor (x, y, window) in sliding_window(image, stepSize=10, windowSize=(winW, winH)):\n",
    "\t\t# if the window does not meet the desired window size, ignore it\n",
    "\t\tif window.shape[0] != winH or window.shape[1] != winW:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\troi = image[y:y + winH, x:x + winW]\n",
    "\n",
    "\t\t# Convert array into PIL Image.\n",
    "\t\tim = Image.fromarray(roi)\n",
    "\t\ttensor_image = img_to_array(im)\n",
    "\t\timgs = [] # must be in the 2d list format, no additional usage.\n",
    "\t\timgs.append(tensor_image)\n",
    "\n",
    "\t\t# predict the region.\n",
    "\t\tpredict_result = model.predict(imgs)\n",
    "\t\tfinal_result = np.argmax(predict_result[0]) # transfer the result to 0 or 1\n",
    "\n",
    "\t\tif final_result == 1:\n",
    "\t\t\trectangle_result.append((x, y))\n",
    "\treturn rectangle_result\n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/envs/py3.4/lib/python3.6/site-packages/tflearn/initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/py3.4/lib/python3.6/site-packages/tflearn/objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "INFO:tensorflow:Restoring parameters from /home/arnold/raindrop-detection-cnn/models/alexnet_30_2_detection.tfl\n",
      "rectangle_result1  [(32, 0, 63, 15), (1116, 0, 1151, 20), (1151, 0, 1184, 27), (1179, 0, 1220, 18), (1213, 0, 1264, 36), (1243, 0, 1279, 28), (307, 203, 356, 228), (429, 208, 494, 228), (495, 208, 564, 228), (673, 192, 718, 225), (707, 204, 740, 227), (756, 195, 796, 228), (843, 208, 884, 228), (885, 208, 930, 226), (53, 224, 116, 272), (165, 224, 194, 266), (252, 227, 290, 260), (291, 221, 322, 260), (323, 229, 353, 258), (381, 229, 416, 260), (447, 229, 481, 260), (481, 219, 514, 258), (512, 229, 546, 260), (547, 219, 578, 260), (579, 223, 610, 259), (611, 219, 642, 257), (639, 223, 670, 260), (671, 221, 702, 260), (703, 221, 738, 260), (738, 205, 768, 260), (767, 229, 804, 256), (863, 221, 900, 260), (901, 224, 944, 260), (939, 224, 970, 244), (944, 224, 1007, 260), (997, 240, 1044, 260), (0, 259, 36, 290), (33, 253, 77, 303), (75, 251, 99, 291), (165, 251, 178, 273), (173, 267, 212, 290), (255, 261, 291, 298), (287, 261, 323, 308), (319, 257, 350, 308), (348, 258, 386, 292), (383, 261, 414, 306), (415, 259, 446, 300), (447, 261, 482, 300), (477, 257, 516, 290), (509, 261, 542, 304), (543, 257, 574, 303), (575, 257, 604, 298), (605, 253, 640, 284), (641, 258, 676, 300), (673, 253, 708, 288), (705, 259, 739, 308), (739, 261, 771, 307), (767, 257, 800, 302), (801, 245, 830, 300), (831, 258, 868, 302), (863, 261, 900, 300), (901, 261, 939, 300), (939, 251, 978, 292), (963, 252, 1010, 287), (995, 261, 1028, 288), (1053, 261, 1092, 308), (1089, 251, 1124, 304), (1124, 269, 1140, 290), (1141, 273, 1164, 284), (1163, 261, 1215, 308), (0, 291, 35, 314), (227, 287, 244, 319), (245, 293, 290, 319), (283, 301, 308, 320), (303, 304, 340, 324), (341, 293, 385, 316), (411, 301, 446, 320), (463, 291, 512, 317), (560, 299, 626, 319), (595, 283, 656, 308), (667, 289, 705, 320), (688, 301, 724, 319), (833, 293, 868, 319), (864, 301, 896, 322), (909, 287, 960, 323), (961, 285, 1012, 314), (997, 286, 1042, 314), (1029, 309, 1034, 314), (1035, 293, 1092, 323), (1259, 293, 1279, 320), (941, 315, 995, 338), (1141, 372, 1152, 382), (773, 389, 778, 396), (284, 405, 304, 452), (1039, 421, 1059, 468), (1163, 402, 1188, 464), (287, 453, 302, 498), (1135, 465, 1154, 516), (287, 557, 304, 607), (773, 592, 816, 640), (1043, 613, 1074, 640)]\n",
      "rectangle_result2  [(1140, 0), (1160, 0), (1170, 0), (1190, 0), (1200, 0), (1210, 0), (1220, 0), (1230, 0), (1240, 0), (1250, 0), (1040, 10), (1050, 10), (1160, 10), (1220, 10), (1230, 10), (1240, 10), (1250, 10), (1240, 20), (1250, 20), (1250, 30), (1100, 40), (1110, 40), (430, 200), (440, 200), (490, 200), (500, 200), (510, 200), (560, 200), (570, 200), (590, 200), (600, 200), (620, 200), (630, 200), (650, 200), (680, 200), (690, 200), (710, 200), (720, 200), (730, 200), (750, 200), (770, 200), (820, 200), (390, 210), (410, 210), (430, 210), (440, 210), (450, 210), (460, 210), (470, 210), (480, 210), (490, 210), (500, 210), (510, 210), (520, 210), (530, 210), (540, 210), (550, 210), (560, 210), (570, 210), (580, 210), (600, 210), (610, 210), (630, 210), (640, 210), (650, 210), (660, 210), (670, 210), (680, 210), (690, 210), (700, 210), (730, 210), (740, 210), (780, 210), (790, 210), (800, 210), (850, 210), (860, 210), (890, 210), (900, 210), (70, 220), (80, 220), (100, 220), (110, 220), (120, 220), (130, 220), (140, 220), (150, 220), (160, 220), (170, 220), (180, 220), (200, 220), (230, 220), (240, 220), (250, 220), (260, 220), (270, 220), (280, 220), (290, 220), (300, 220), (310, 220), (320, 220), (330, 220), (340, 220), (350, 220), (360, 220), (370, 220), (380, 220), (390, 220), (400, 220), (410, 220), (420, 220), (430, 220), (440, 220), (450, 220), (460, 220), (470, 220), (480, 220), (490, 220), (500, 220), (510, 220), (520, 220), (530, 220), (540, 220), (550, 220), (560, 220), (570, 220), (580, 220), (590, 220), (600, 220), (610, 220), (620, 220), (630, 220), (640, 220), (650, 220), (660, 220), (670, 220), (680, 220), (690, 220), (700, 220), (710, 220), (720, 220), (730, 220), (740, 220), (750, 220), (760, 220), (770, 220), (780, 220), (790, 220), (800, 220), (810, 220), (820, 220), (830, 220), (840, 220), (850, 220), (860, 220), (870, 220), (880, 220), (890, 220), (900, 220), (60, 230), (70, 230), (80, 230), (90, 230), (100, 230), (110, 230), (120, 230), (130, 230), (140, 230), (150, 230), (160, 230), (170, 230), (180, 230), (190, 230), (200, 230), (210, 230), (220, 230), (230, 230), (240, 230), (250, 230), (260, 230), (270, 230), (280, 230), (290, 230), (300, 230), (310, 230), (320, 230), (330, 230), (340, 230), (350, 230), (360, 230), (370, 230), (380, 230), (390, 230), (400, 230), (410, 230), (420, 230), (430, 230), (440, 230), (450, 230), (460, 230), (470, 230), (480, 230), (490, 230), (500, 230), (510, 230), (520, 230), (530, 230), (540, 230), (550, 230), (560, 230), (570, 230), (580, 230), (590, 230), (600, 230), (610, 230), (620, 230), (630, 230), (640, 230), (650, 230), (660, 230), (670, 230), (680, 230), (690, 230), (700, 230), (710, 230), (720, 230), (730, 230), (740, 230), (750, 230), (760, 230), (770, 230), (780, 230), (790, 230), (800, 230), (810, 230), (820, 230), (830, 230), (840, 230), (850, 230), (860, 230), (870, 230), (880, 230), (890, 230), (900, 230), (910, 230), (920, 230), (930, 230), (940, 230), (950, 230), (960, 230), (970, 230), (980, 230), (10, 240), (20, 240), (30, 240), (40, 240), (50, 240), (60, 240), (70, 240), (90, 240), (120, 240), (130, 240), (150, 240), (160, 240), (170, 240), (180, 240), (190, 240), (200, 240), (210, 240), (220, 240), (230, 240), (240, 240), (250, 240), (260, 240), (270, 240), (280, 240), (290, 240), (300, 240), (310, 240), (320, 240), (330, 240), (340, 240), (350, 240), (360, 240), (370, 240), (380, 240), (390, 240), (400, 240), (410, 240), (420, 240), (430, 240), (440, 240), (450, 240), (460, 240), (470, 240), (480, 240), (490, 240), (500, 240), (510, 240), (520, 240), (530, 240), (540, 240), (550, 240), (560, 240), (570, 240), (580, 240), (590, 240), (600, 240), (610, 240), (620, 240), (630, 240), (640, 240), (650, 240), (660, 240), (670, 240), (680, 240), (690, 240), (700, 240), (710, 240), (720, 240), (730, 240), (740, 240), (750, 240), (760, 240), (770, 240), (780, 240), (790, 240), (800, 240), (810, 240), (820, 240), (830, 240), (840, 240), (850, 240), (860, 240), (870, 240), (880, 240), (890, 240), (900, 240), (910, 240), (920, 240), (930, 240), (940, 240), (950, 240), (960, 240), (970, 240), (980, 240), (990, 240), (1000, 240), (1010, 240), (1020, 240), (1030, 240), (1040, 240), (1050, 240), (1060, 240), (1070, 240), (1100, 240), (1110, 240), (0, 250), (10, 250), (20, 250), (30, 250), (40, 250), (50, 250), (60, 250), (70, 250), (80, 250), (90, 250), (100, 250), (110, 250), (130, 250), (140, 250), (150, 250), (170, 250), (180, 250), (190, 250), (200, 250), (210, 250), (220, 250), (230, 250), (240, 250), (250, 250), (260, 250), (270, 250), (280, 250), (290, 250), (300, 250), (310, 250), (320, 250), (330, 250), (340, 250), (350, 250), (360, 250), (370, 250), (380, 250), (390, 250), (400, 250), (410, 250), (420, 250), (430, 250), (440, 250), (450, 250), (460, 250), (470, 250), (480, 250), (490, 250), (500, 250), (510, 250), (520, 250), (530, 250), (540, 250), (550, 250), (560, 250), (570, 250), (580, 250), (590, 250), (600, 250), (610, 250), (620, 250), (630, 250), (640, 250), (650, 250), (660, 250), (670, 250), (680, 250), (690, 250), (700, 250), (710, 250), (720, 250), (730, 250), (740, 250), (750, 250), (760, 250), (770, 250), (780, 250), (790, 250), (800, 250), (810, 250), (820, 250), (830, 250), (840, 250), (850, 250), (860, 250), (870, 250), (880, 250), (890, 250), (900, 250), (910, 250), (920, 250), (930, 250), (940, 250), (950, 250), (960, 250), (970, 250), (980, 250), (990, 250), (1000, 250), (1010, 250), (1020, 250), (1030, 250), (1040, 250), (1050, 250), (1060, 250), (1080, 250), (1090, 250), (1100, 250), (1120, 250), (1150, 250), (0, 260), (10, 260), (20, 260), (50, 260), (60, 260), (70, 260), (170, 260), (190, 260), (200, 260), (210, 260), (220, 260), (230, 260), (240, 260), (250, 260), (260, 260), (270, 260), (280, 260), (290, 260), (300, 260), (310, 260), (320, 260), (330, 260), (340, 260), (350, 260), (360, 260), (370, 260), (380, 260), (390, 260), (400, 260), (410, 260), (420, 260), (430, 260), (440, 260), (450, 260), (460, 260), (470, 260), (480, 260), (490, 260), (500, 260), (510, 260), (520, 260), (530, 260), (540, 260), (550, 260), (560, 260), (570, 260), (580, 260), (590, 260), (600, 260), (610, 260), (620, 260), (630, 260), (640, 260), (650, 260), (660, 260), (670, 260), (680, 260), (690, 260), (700, 260), (710, 260), (720, 260), (730, 260), (740, 260), (750, 260), (760, 260), (770, 260), (780, 260), (790, 260), (800, 260), (810, 260), (820, 260), (830, 260), (840, 260), (850, 260), (860, 260), (870, 260), (880, 260), (890, 260), (900, 260), (910, 260), (920, 260), (930, 260), (940, 260), (950, 260), (960, 260), (970, 260), (980, 260), (990, 260), (1000, 260), (1010, 260), (1020, 260), (1030, 260), (1040, 260), (1050, 260), (1060, 260), (1090, 260), (1100, 260), (1110, 260), (1120, 260), (1130, 260), (1140, 260), (1150, 260), (1160, 260), (0, 270), (10, 270), (20, 270), (30, 270), (40, 270), (50, 270), (60, 270), (210, 270), (220, 270), (230, 270), (240, 270), (250, 270), (260, 270), (270, 270), (280, 270), (290, 270), (300, 270), (310, 270), (320, 270), (330, 270), (340, 270), (350, 270), (360, 270), (370, 270), (380, 270), (390, 270), (400, 270), (410, 270), (420, 270), (430, 270), (440, 270), (450, 270), (460, 270), (470, 270), (480, 270), (490, 270), (500, 270), (510, 270), (520, 270), (530, 270), (540, 270), (550, 270), (560, 270), (570, 270), (580, 270), (590, 270), (600, 270), (610, 270), (620, 270), (630, 270), (640, 270), (650, 270), (660, 270), (670, 270), (680, 270), (690, 270), (700, 270), (710, 270), (720, 270), (730, 270), (740, 270), (750, 270), (760, 270), (770, 270), (780, 270), (790, 270), (800, 270), (810, 270), (820, 270), (830, 270), (840, 270), (850, 270), (860, 270), (870, 270), (880, 270), (890, 270), (900, 270), (910, 270), (920, 270), (930, 270), (940, 270), (950, 270), (960, 270), (970, 270), (980, 270), (990, 270), (1000, 270), (1010, 270), (1020, 270), (1030, 270), (1040, 270), (1050, 270), (1060, 270), (1070, 270), (1080, 270), (1090, 270), (1100, 270), (1120, 270), (1140, 270), (1160, 270), (1170, 270), (1180, 270), (1190, 270), (1200, 270), (1210, 270), (1220, 270), (1230, 270), (1240, 270), (1250, 270), (10, 280), (30, 280), (40, 280), (50, 280), (60, 280), (210, 280), (220, 280), (230, 280), (240, 280), (250, 280), (260, 280), (270, 280), (280, 280), (290, 280), (300, 280), (310, 280), (320, 280), (330, 280), (340, 280), (350, 280), (360, 280), (370, 280), (380, 280), (390, 280), (400, 280), (410, 280), (420, 280), (430, 280), (440, 280), (450, 280), (460, 280), (470, 280), (480, 280), (490, 280), (500, 280), (510, 280), (520, 280), (530, 280), (540, 280), (550, 280), (560, 280), (570, 280), (580, 280), (590, 280), (600, 280), (610, 280), (620, 280), (630, 280), (640, 280), (650, 280), (660, 280), (670, 280), (680, 280), (690, 280), (700, 280), (710, 280), (720, 280), (730, 280), (740, 280), (750, 280), (760, 280), (770, 280), (780, 280), (790, 280), (800, 280), (810, 280), (820, 280), (830, 280), (840, 280), (850, 280), (860, 280), (870, 280), (880, 280), (890, 280), (900, 280), (910, 280), (920, 280), (930, 280), (940, 280), (950, 280), (960, 280), (970, 280), (980, 280), (990, 280), (1000, 280), (1010, 280), (1020, 280), (1030, 280), (1040, 280), (1050, 280), (1060, 280), (1070, 280), (1080, 280), (1090, 280), (1140, 280), (1200, 280), (1210, 280), (1220, 280), (1230, 280), (1240, 280), (1250, 280), (0, 290), (210, 290), (220, 290), (230, 290), (240, 290), (250, 290), (260, 290), (270, 290), (290, 290), (300, 290), (310, 290), (320, 290), (330, 290), (340, 290), (350, 290), (360, 290), (370, 290), (380, 290), (390, 290), (400, 290), (420, 290), (430, 290), (450, 290), (460, 290), (470, 290), (480, 290), (490, 290), (500, 290), (510, 290), (520, 290), (550, 290), (560, 290), (570, 290), (580, 290), (590, 290), (600, 290), (610, 290), (620, 290), (630, 290), (640, 290), (660, 290), (670, 290), (680, 290), (690, 290), (700, 290), (710, 290), (720, 290), (730, 290), (760, 290), (770, 290), (780, 290), (790, 290), (800, 290), (810, 290), (820, 290), (830, 290), (840, 290), (860, 290), (870, 290), (880, 290), (900, 290), (910, 290), (920, 290), (930, 290), (940, 290), (950, 290), (960, 290), (970, 290), (980, 290), (990, 290), (1000, 290), (1010, 290), (1020, 290), (1030, 290), (1040, 290), (1050, 290), (1060, 290), (1070, 290), (1180, 290), (1200, 290), (1210, 290), (1220, 290), (1230, 290), (1250, 290), (200, 300), (220, 300), (260, 300), (300, 300), (820, 300), (890, 300), (900, 300), (910, 300), (920, 300), (930, 300), (940, 300), (950, 300), (960, 300), (970, 300), (980, 300), (990, 300), (1000, 300), (1020, 300), (1030, 300), (1040, 300), (950, 310), (960, 310), (970, 310), (980, 310), (990, 310), (1230, 340), (300, 360), (410, 360), (510, 360), (1070, 360), (790, 380), (460, 390), (1110, 400), (1120, 400), (1110, 410), (1120, 410), (1120, 420), (1160, 430), (300, 440), (1190, 440), (1250, 440), (1040, 450), (1190, 450), (1040, 460), (1160, 460), (1190, 460), (1220, 460), (1250, 460), (300, 470), (1030, 470), (1040, 470), (1160, 470), (1220, 490), (1080, 520), (1100, 530), (1110, 530), (1030, 550), (1070, 570), (1090, 580), (1020, 590), (1010, 620), (860, 640), (1060, 640), (1100, 670), (1050, 680), (1100, 680), (870, 690), (1090, 690)]\n"
     ]
    }
   ],
   "source": [
    "# Initialise the AlexNet and load the trained model for the CNN.\n",
    "alex_net = create_basic_alexnet()\n",
    "model = tflearn.DNN(alex_net)\n",
    "model.load(model_path, weights_only = True)\n",
    "\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Get the proposed regions\n",
    "rectangle_result1 = super_pixel(image)\n",
    "print(\"rectangle_result1 \", rectangle_result1)\n",
    "rectangle_result2 = cnn_find_raindrop(image, 30, 30)\n",
    "print(\"rectangle_result2 \", rectangle_result2)\n",
    "\n",
    "\n",
    "# # **************** Draw Optimized Rectangles *******************\n",
    "# We don't want to draw the detection rectangles directly on the original image,\n",
    "# we copy the image and draws the rectangels on the copied image.\n",
    "# clone = image.copy()\n",
    "\n",
    "# for element in rectangle_result:\n",
    "# \tcv2.rectangle(clone,(element[0], element[1]),(element[2],element[3] ),(0, 255, 0),2)\n",
    "# ## *************************************************************\n",
    "\n",
    "\n",
    "\n",
    "# # ********** Draw the rectangles that contains ground truth raindrops ********\n",
    "# if ground_truth:\n",
    "# \t# Parse the xml file that contains raindrop locations of the image\n",
    "# \txml_golden = parse_xml_file(ground_truth_xml_path)\n",
    "# \t# Read the coordinates of the raindrops\n",
    "# \txml_reformat = xml_transform(xml_golden)\n",
    "# \t# *************** Draw the XML Result ********************\n",
    "# \tfor element in xml_reformat:\n",
    "# \t\tcv2.rectangle(clone,(element[0], element[1]),(element[2],element[3] ),(0, 0, 255),2)\n",
    "# \t# ********************************************************\n",
    "\n",
    "\n",
    "# # Save the result image into a folder.\n",
    "# print(result_path)\n",
    "# cv2.imwrite(result_path, clone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
